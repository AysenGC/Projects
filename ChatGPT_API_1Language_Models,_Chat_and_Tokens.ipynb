{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOxKwUwUxL9mKl7AcQ5cvUR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AysenGC/Projects/blob/main/ChatGPT_API_1Language_Models%2C_Chat_and_Tokens.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R5XO_xi2TiHz"
      },
      "outputs": [],
      "source": [
        "#Setup-Load the API key and relevant Python libaries.\n",
        "import os\n",
        "import openai\n",
        "!pip install tiktoken\n",
        "import tiktoken  #The tiktoken library is an open-source tool developed by OpenAI to tokenize text\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "_ = load_dotenv(find_dotenv()) # read local .env file\n",
        "\n",
        "openai.api_key  = os.environ['OPENAI_API_KEY']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Helper funciton\n",
        "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
        "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=0,\n",
        "    )\n",
        "    return response.choices[0].message[\"content\"]"
      ],
      "metadata": {
        "id": "nzCDhU9FUErg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Prompt a model and get a completion\n",
        "response = get_completion(\"What is the capital of France?\")\n",
        "print(response)"
      ],
      "metadata": {
        "id": "LUoNPU4LWAPb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Tokens\n",
        "response = get_completion(\"Take the letters in lollipop \\\n",
        "and reverse them\")\n",
        "print(response)"
      ],
      "metadata": {
        "id": "p6M6A9zwWVli"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = get_completion(\"\"\"Take the letters in \\\n",
        "l-o-l-l-i-p-o-p and reverse them\"\"\")\n",
        "print(response)"
      ],
      "metadata": {
        "id": "Z5gEf0V4Wi40"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Helper function for the chat format\n",
        "def get_completion_from_messages(messages,\n",
        "                                 model=\"gpt-3.5-turbo\",\n",
        "                                 temperature=0,\n",
        "                                 max_tokens=500):\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=temperature, # this is the degree of randomness of the model's output\n",
        "        max_tokens=max_tokens, # the maximum number of tokens the model can ouptut\n",
        "    )\n",
        "    return response.choices[0].message[\"content\"]\n"
      ],
      "metadata": {
        "id": "mqfwrHqcXNwi"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages =  [\n",
        "{'role':'system',\n",
        " 'content':\"\"\"You are an assistant who\\\n",
        " responds in the style of Dr Seuss.\"\"\"},\n",
        "{'role':'user',\n",
        " 'content':\"\"\"write me a very short poem\\\n",
        " about a happy carrot\"\"\"},\n",
        "]\n",
        "response = get_completion_from_messages(messages, temperature=1)\n",
        "print(response)"
      ],
      "metadata": {
        "id": "AZff5gcIXioe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Length\n",
        "messages =  [\n",
        "{'role':'system',\n",
        " 'content':'All your responses must be \\\n",
        "one sentence long.'},\n",
        "{'role':'user',\n",
        " 'content':'write me a story about a happy carrot'},\n",
        "]\n",
        "response = get_completion_from_messages(messages, temperature =1)\n",
        "print(response)"
      ],
      "metadata": {
        "id": "GR_iJmqpX-nm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Combined\n",
        "messages =  [\n",
        "{'role':'system',\n",
        " 'content':\"\"\"You are an assistant who \\\n",
        "responds in the style of Dr Seuss. \\\n",
        "All your responses must be one sentence long.\"\"\"},\n",
        "{'role':'user',\n",
        " 'content':\"\"\"write me a story about a happy carrot\"\"\"},\n",
        "]\n",
        "response = get_completion_from_messages(messages,\n",
        "                                        temperature =1)\n",
        "print(response)"
      ],
      "metadata": {
        "id": "RoAZ3GfLYEjT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_completion_and_token_count(messages,\n",
        "                                   model=\"gpt-3.5-turbo\",\n",
        "                                   temperature=0,\n",
        "                                   max_tokens=500):\n",
        "\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=temperature,\n",
        "        max_tokens=max_tokens,\n",
        "    )\n",
        "\n",
        "    content = response.choices[0].message[\"content\"]\n",
        "\n",
        "    token_dict = {\n",
        "'prompt_tokens':response['usage']['prompt_tokens'],\n",
        "'completion_tokens':response['usage']['completion_tokens'],\n",
        "'total_tokens':response['usage']['total_tokens'],\n",
        "    }\n",
        "\n",
        "    return content, token_dict"
      ],
      "metadata": {
        "id": "xlrOIPmpYJeJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "{'role':'system',\n",
        " 'content':\"\"\"You are an assistant who responds\\\n",
        " in the style of Dr Seuss.\"\"\"},\n",
        "{'role':'user',\n",
        " 'content':\"\"\"write me a very short poem \\\n",
        " about a happy carrot\"\"\"},\n",
        "]\n",
        "response, token_dict = get_completion_and_token_count(messages)"
      ],
      "metadata": {
        "id": "GwAIp0ZaYN9l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response)"
      ],
      "metadata": {
        "id": "hWNd15luYQ_G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(token_dict)"
      ],
      "metadata": {
        "id": "kpby9BeKYTR9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notes on using the API:\n",
        "\n",
        "\"\n",
        "To install the OpenAI Python library:\n",
        "\n",
        "!pip install openai\n",
        "The library needs to be configured with your account's secret key, which is available on the website.\n",
        "\n",
        "You can either set it as the OPENAI_API_KEY environment variable before using the library:\n",
        "\n",
        " !export OPENAI_API_KEY='sk-...'\n",
        "Or, set openai.api_key to its value:\n",
        "\n",
        "import openai\n",
        "openai.api_key = \"sk-...\"\n",
        "\n",
        "\n",
        "Notes on using backslash \"\\\":\n",
        "\n",
        "A backslash \\ is used to make the text fit on the screen without inserting newline '\\n' characters.\n",
        "\n",
        "GPT-3 isn't really affected whether you insert newline characters or not. But when working with LLMs in general, you may consider whether newline characters in your prompt may affect the model's performance.\n",
        "\n",
        "\"\n",
        "\n",
        "Source: https://learn.deeplearning.ai/chatgpt-building-system/lesson/2/language-models,-the-chat-format-and-tokens"
      ],
      "metadata": {
        "id": "KGrFyQPSYZhw"
      }
    }
  ]
}