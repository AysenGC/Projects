{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Capstone 2 Final Project Report.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNJRFDClebso0/5Zs51vN+A",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AysenGC/Projects/blob/main/Copy_of_Capstone_2_Final_Project_Report.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Predicting the IMDb scores of the Netflix Movies and Series according to the genre and tags with the help of the NLP and ML algorithms\n"
      ],
      "metadata": {
        "id": "alMdeLHb4FHk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1.Introduction"
      ],
      "metadata": {
        "id": "nt5g75W04A5K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Netflix Inc.(NFLX:NASDAQ) founded in 1997 by Marc Randolph and Reed Hastings as a rent-DVD-by-mail service that used the pay-for-rent model, and now turned into one of the most popular online entertainment platform.\n",
        "\n",
        "####As of 2022, there are 220 million Netflix subscribers, and half of the Americans prefer Netflix over any other video streaming service.\n",
        "\n",
        "####Netflix is heavily invested in developing machine learning research to maximize the user satisfaction and keep them hooked. And it can now set up 1,300 recommendation clusters, based on viewing preferences.\n"
      ],
      "metadata": {
        "id": "FSINAAML3chD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2.Data"
      ],
      "metadata": {
        "id": "n2YhGGSr9Trd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####The dataset is an artificial Kaggle dataset created by Ashish Gupta by using 4 APIs, includes 29 features, lastly updated in April 2021, has a license in public domain.\n",
        "####This dataset consists of one large cvs file and combines data sources from Netflix, Rotten Tomatoes, IMBD, posters, box office information, trailers on YouTube, and more.  Note: There is no official Netflix API.\n",
        "####The dataset is great for curious intermediate level data scientists who wants to discover the correlations between different ratings, actors, directors, box office etc. It is also great for data scientists and engineers who wants to dive into deep learning areas like NLP, image processing etc. \n"
      ],
      "metadata": {
        "id": "nSYFXvFyAABZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3. Problem Statement"
      ],
      "metadata": {
        "id": "TH0g0U90Arjr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####The goal of the project is to answer which tags & genres of series and movies streamed on Netflix achieve highest likeability/quality(IMDb score). \n",
        "\n",
        "####Note 1: IMDb is the world’s most popular source for movie, TV and celebrity content.The answer of the question would be beneficial for Netflix to understand  which categories of genre and tags are worth investing. \n",
        "\n",
        "####Note 2: IMDb score interpretation: If an IMDb score is 7.5, then it is within the top 25% of movies.\n",
        "\n"
      ],
      "metadata": {
        "id": "R3SFhZYAAxU3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The original dataset has 29 columns and 15480 non-null entries. "
      ],
      "metadata": {
        "id": "G9d3alzRT07g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src='https://drive.google.com/uc?id=1M8XzFxD8ucWMOsU-JEfJ9HoU2JCNutin' width='400' height='500'>\n"
      ],
      "metadata": {
        "id": "IXMrjwkIrFqT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####The columns \"Netflix Link\", \"IMDb Link\", \"Summary\", \"Image\", \"Poster\", \"TMDb Trailer\", \"Trailer Site\" were found unnecessary for this analysis and eliminated from the dataframe. \n",
        "\n",
        "####As a rule of thumb, if a column has NAN values over %60-70, it should also be dropped. Following the investigation of the ratio of the NaN values, the columns \"Metacritic Score\" and \"Boxoffice\" got also eliminated."
      ],
      "metadata": {
        "id": "32zl31tUtEeA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####The unique values in each remaining column are investigated. Tags are intended to describe the specific details about a movie/series that from time to time overlaps with genre or genre subcategories.\n",
        "\n",
        "####It turns out that the genre and tags have many subgroups. A movie or a series can be in multiple subgroups."
      ],
      "metadata": {
        "id": "R-Y2KZK3yt33"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##5.EDA"
      ],
      "metadata": {
        "id": "gJ3LGpxj_rwX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "####The necessary python libraries pandas, numpy, matplotlib, seaborn and plotly library of R were imported.\n",
        "####With descriptive statistics, the numerical features were investigated. Mean, standard deviation, min-max values as well as first quartile to third quantile were calculated."
      ],
      "metadata": {
        "id": "9i_4Qd6JA90M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src='https://drive.google.com/uc?id=1QVcyEZeFw2RR20TYBHp15tDxTcTpfzDa' width='500' height='280'>"
      ],
      "metadata": {
        "id": "Cf6R8mKvCp2q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####For the next steps, I decided to create 2 seperate dataframes: one for TV Series, one for Movies. \n",
        "\n",
        "####One of the important steps of the EDA is examining the distribution of the numerical data and pointing out the outliers through visualization and mathematical approach. After removing the Nan values, the dataset becomes ready to check out the outliers.\n",
        "\n",
        "####Note: Amputation methods like replacing the Nan values with mean, median, or mode would not work here since each movie's or series's rating is specific and defines its quality.\n",
        "\n",
        "####Boxplots can communicate a lot of information: min, max, outliers, percentiles, median...Z score describes the Taking a Z-score is simply mapping the data onto a distribution whose mean is defined as 0 and whose standard deviation is defined as 1.\n",
        "\n",
        "####The goal of taking Z-scores is to remove the effects of the location and scale of the data, allowing different datasets to be compared directly. \n",
        "\n",
        "####The intuition behind the Z-score method of outlier detection is that, once we’ve centred and rescaled the data, anything that is too far from zero (the threshold is usually a Z-score of 3 or -3) should be considered an outlier.\n",
        "\n",
        "####The data was rescaled through normalization. MinMaxScaler() from sklearn liibrary was used to transform all variables in the data to the same range. It did not solve the problem caused by outliers, so I dealt with the outliers as a next step.\n"
      ],
      "metadata": {
        "id": "wcKeeBTLDCnE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src='https://drive.google.com/uc?id=1r3tOJ2sOIV0SMsvfVANkqetszKRzvSKU' width='600' height='450'>\n"
      ],
      "metadata": {
        "id": "mR0ZjQpVNTJq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src='https://drive.google.com/uc?id=1DYGTLUylawn1K0HA4Jd3ajPAkhjECa61' width='600' height='450'>\n"
      ],
      "metadata": {
        "id": "266j8ooTpr7D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####The presence of outliers in votes/awards/ratings actually makes sense. Good movies and series ratings/scores are way different than the mean ratings/scores, that is what makes them \"good\"."
      ],
      "metadata": {
        "id": "FzDBtIN5qBIU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Heatmaps are an efficient way of demonstrating the correlation between two variables, one plotted on each axis. \n",
        "####By observing how cell colors change across each axis of the correlogram, you can observe if there are any patterns in value for one or both variables. The darker colors below represent higher correlation while lighter colors represent weaker correlation."
      ],
      "metadata": {
        "id": "S5c4JT-9qXyP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####The heatmap below shows the relationship among all the values of TV Series dataframe:\n"
      ],
      "metadata": {
        "id": "xnAfnJXTrwi-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src='https://drive.google.com/uc?id=1h0U1iPBR-AovscWxRX9Sso_W9UCz6dGt' width='500' height='400'>\n",
        "\n"
      ],
      "metadata": {
        "id": "O9x4avjhtJF5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####In TV Series, Hidden Gem Score and Rotten Tomatoes Score are positively correlated. \n",
        "####IMDb Score is strongly correlated with Rotten Tomatoes Score.\n",
        "####It is highly likely that a TV Series formerly nominated for award gets the award.\n",
        "####The series that were nominated and received award gets high IMDb score and IMDb votes.\n",
        "####Awards and nominations are not correlated with Hidden Gem Score."
      ],
      "metadata": {
        "id": "1cIxC6pUuKwL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####The heatmap below shows the relationship among all the values of Movies dataframe:\n",
        "\n",
        "<img src='https://drive.google.com/uc?id=1-YzQlAZHIsJv78pps-kTwPIOQYTndzTM' width='500' height='400'>\n",
        "\n"
      ],
      "metadata": {
        "id": "Hh03NnjMtgBD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####In Movies, the Hidden Gem Score is positively correlated with Rotten Tomatoes Score.\n",
        "####It is highly likely that a movie formerly nominated for award gets the award.\n",
        "####Nominated and rewarded movies gets high IMDb votes & Score.\n",
        "####Awards and nominations are not correlated with Hidden Gem Score and they are weakly positively correlated with Rotten Tomatoes Score. "
      ],
      "metadata": {
        "id": "9NRKGaClvJb2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####The next investigation is about finding the most frequently appearing genres and tags for both TV Series and Movies.\n",
        "\n",
        "####Wordcloud recently has become a very popular tool of data visualization. Although it might be insufficient for a deep analytical study, it is an easy and effective illustrative tool.It gives greater prominence to words that appear more frequently in a source text. "
      ],
      "metadata": {
        "id": "IMCORmUTvvVH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src='https://drive.google.com/uc?id=1wEYk1h7Oc8VpTj22RDCix6rt3MFqeat0' width='500' height='300'>\n"
      ],
      "metadata": {
        "id": "reGn_mvZC9y0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src='https://drive.google.com/uc?id=1R7vyDWVDVT5QlCTga6IiUtAXrHIC3hvs' width='500' height='300'>\n"
      ],
      "metadata": {
        "id": "7vdYQY3NDjjQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src='https://drive.google.com/uc?id=1E8eSOnHlNsHPjjNEDNxXQJp_K0OkLIRq' width='500' height='300'>\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5fvcf6xkDxPz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src='https://drive.google.com/uc?id=1GMAwSKo1PjT7I5AsiYVgM4DsQhCrhldH' width='500' height='300'>\n"
      ],
      "metadata": {
        "id": "lLbnRcsKDfuM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##6.Feature Engineering & Pre-processing"
      ],
      "metadata": {
        "id": "O_wSMuh_EyKk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####The goal in this section is to use the Natural Language Processing(NLP) methods to prepare the data for machine learning modeling by feature extraction. \n",
        "\n",
        "####The necessary pyhton packages of sklearn library were used.\n",
        "\n",
        "####Text cleaning step of feature engineering varies from dataset to dataset. Here, the tags and genre categorizations were combined together. And then, strings were converted into lowercase and punctuation(comma) is removed. Then, the strings were splitted into \"tokens\".The stopwords, which were the words that were quite repetitive and have no meaning, got removed. One drawback of this dataset is that there are titles, genres and tags in multiple languages and the only stopwords that I removed are in English. Just like in English, there are stopwords in every language, and there are suitable packages to filter them out. \n",
        "\n",
        "####After tokenization, the next step was using the tf-idf vectorizer algorithm from scikit library.\n",
        "####A tf-idf vectorizer combines and performs two concepts: term frequency and inverse document frequency. A term frequency(tf) gives how many times a term has occured in a document(corpus). An inverse document frequency(idf) gives how significant a term is in a corpus. The mathematical formulas are like the following(Source:Medium [link text](https://medium.com/analytics-vidhya/tf-idf-term-frequency-technique-easiest-explanation-for-text-classification-in-nlp-with-code-8ca3912e58c3)):\n",
        "\n",
        "<img src='https://drive.google.com/uc?id=1Q8gSeaApibAp0Lf0KfiIvKB1Uq7Gffxi' width='500' height='200'>\n",
        "\n",
        "####A tf-idf is the multiplication and normalizaiton of both values together.And the output looks as the following:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ucWH2dD6GKHB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##7.Modeling\n"
      ],
      "metadata": {
        "id": "7i3tlV0sFZTi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###7.1 Logistic Regression\n",
        "\n",
        "Logistic Regression Model is considered as an efficient model for binary  classification problems. Unlike linear regression, a linear relationship between dependent and independent variable is not necessary.\n",
        "\n",
        "I used the logistic regression model to find out the probability of tags/genre categories end up as 0(%75 or unpopular) or 1(25% or popular). \n",
        "\n",
        "####7.1.1.Logistic Regression Classification Report \n",
        "\n",
        "Classification Report for TV Series:\n",
        "\n",
        "<img src='https://drive.google.com/uc?id=1Rb7DoqL9Dh89nDqwf-ZSbkwtoGYlJg5X' width='500' height='200'>\n",
        "\n",
        "\n",
        "Classification Report for Movies:\n",
        "\n",
        "<img src='https://drive.google.com/uc?id=1aTX6aYzL-nPUwsS0eXFadNE5ZkER3wwM' width='500' height='200'>\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "DaWx0XALFjwB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy and precision are two measures of observational error. Accuracy is how close or far off a given set of measurements (observations or readings) are to their true value, while precision is how close or dispersed the measurements are to each other(Wikipedia).\n",
        "\n",
        "Precision (also called positive predictive value) is the fraction of relevant instances among the retrieved instances, while recall (also known as sensitivity) is the fraction of relevant instances that were retrieved. Both precision and recall are therefore based on relevance(Wikipedia).\n",
        "\n",
        "The f-1 score which is the harmonic mean of precision and recall. F1 tells if the classifier is actually good at identifying members of a class, or if it is just identifying everything as a member of a large class.\n",
        "\n",
        "How to interpret these values? \n",
        "\n",
        "The classification report for TV Series shows that the recall is higher than the precision when it comes to categorizing the 0's. High recall means that an algorithm returns most of the relevant results (whether or not irrelevant ones are also returned).A high precision relates to a low false positive rate, and high recall relates to a low false negative rate. There is lower false positives in classifying 0's than 1's.\n",
        "\n",
        "The classification report for Movies shows that the performance of the classification is ideal(1.0)."
      ],
      "metadata": {
        "id": "VzlcqPK3ktVl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###7.2 Random Forest Classifier\n",
        "\n",
        "7.2.1. Random Forest Classifier Feature Importance Rankings & Model Evaluations\n",
        "\n",
        "\n",
        "Ranking for TV Series:\n",
        "\n",
        "<img src='https://drive.google.com/uc?id=1EO4foAvNXfkfNmnwbXCeZCEFUQ1PNCS5' width='300' height='350'>\n",
        "\n",
        "<img src='https://drive.google.com/uc?id=1gCBrnM-tw4wV0xNu5oOjjBRv1ZzYvWTK' width='350' height='350'>\n",
        "\n",
        "\n",
        "Ranking for Movies:\n",
        "\n",
        "<img src='https://drive.google.com/uc?id=1AlkuLVdp68uEoqUDvBOKXuPaKucfswWZ' width='300' height='350'>\n",
        "\n",
        "\n",
        "<img src='https://drive.google.com/uc?id=1DubiIjjMEzKZD2JD4zAn9d5nbp4Y6_Vy' width='350' height='350'>\n",
        "\n",
        "\n",
        "7.2.2. Random Forest Classifier Confusion Matrix & Classification Report \n",
        "\n",
        "Confusion Matrix & Classification Report for TV Series:\n",
        "\n",
        "<img src='https://drive.google.com/uc?id=1ciqqapjMH3j-WrWDWqf0RyZoeqMm_TIe' width='300' height='210'>\n",
        "\n",
        "\n",
        "Confusion Matrix & Classification Report for Movies:\n",
        "\n",
        "<img src='https://drive.google.com/uc?id=1h8_DutgjQAxcWmNhIoViP-gXem-oRxzZ' width='300' height='210'>\n",
        "\n",
        "The classification report of Random Forest Classifier for TV Series highlights that the model correctly identifies 85% of the 0's and 33% of the 1's. The model predicts %68 at a time that a feature results in class 0, %57 at a time that a feature results in class 1.\n",
        "\n",
        "The classification report of Random Forest Classifier for Moviesbrings out that the model correctly identifies 99% of 0's and 8% of 1's. This is the case due to the imbalance between the number of 0 and 1's.\n",
        "\n",
        "\n",
        "Note that accuracy is not a good measure of classifier performance when the classes are so imbalanced. Also note that the precision and recall are inversely related.\n"
      ],
      "metadata": {
        "id": "5GOqs-DtFh_Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##8.Future Improvements & Conclusion "
      ],
      "metadata": {
        "id": "-WoXWhznFlzy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "8.1. Improvements for Feature Engineering & Preprocessing\n",
        "\n",
        "There is a lot of room for improvement:\n",
        "\n",
        "*   Some features are very repetitive in the dataset. Some genre and tags are similar, so when tags and genres combined, their weight among the dataset increase dramatically.\n",
        "*   The tf-idf vectorizer function can include max_df, min_df and max_features and stopwords of other languages. \n",
        "\n",
        "8.2. Improvements for Modeling\n",
        "\n",
        "Both logistic regression and random forest classifier are considered as efficient models in NLP problems.\n",
        "\n",
        "While logistic regression tends to be more sensitive to overfitting and outliers, random forest model is more robust to overfitting and outliers. \n",
        "In this project, random forest classifier and logistic regression performed similarly.\n",
        "\n",
        "A cleaner dataset would allow the ML models to learn the significant features and not biased toward certain repetitive features.\n",
        "\n",
        "Defining a maximum depth of the trees, changing the number of estimators(trees), setting a limit to the numbeer of features at each node split could significantly improve the random forest model.\n",
        "\n",
        "Doing cross-validation after each change would help me to identify which changes are improving the accuracy and overall performance of the model.\n",
        "\n"
      ],
      "metadata": {
        "id": "BKN9En-TNf9e"
      }
    }
  ]
}